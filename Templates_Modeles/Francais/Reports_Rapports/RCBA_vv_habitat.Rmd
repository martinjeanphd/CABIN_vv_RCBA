---
date: '2017-11-01'
output:
  html_notebook:
    df_print: paged
    number_sections: yes
    toc: yes
    toc_float: yes
  html_document:
    df_print: paged
    toc: yes
  word_document:
    toc: yes
version: '1.1'
---

| ![](../../../Configuration/gc_fr.png)  |  ![](../../../Configuration/rcba_logo.png) |
|:------------------------------------|--------------------------------------:|                            


#VÉRIFICATION ET VALIDATION RCBA - DONNÉES D'HABITAT

*Environnement et changement climatique Canada*

*Analyse réalisée le `r Sys.time()`*

***

Ce document est un carnet de note écrit en [Markdown R](http://rmarkdown.rstudio.com). Lorsque vous éxécuter le code intégré au carnet, les résulats apparaitront sous le code correspondant.

Ce rapport présente les résultats de la vérification et la validation des données d'habitat pour le projet **`r paste(datasetName)`**.

Dans cette analyse, le jeu de descripteurs d'habitat sera vérifié pour répondre à la question suivante :
  
  + Les données d'habitat correspondent-elles bien à ce qui a été observé sur le terrain ?

Ce document est un carnet de notes [R Markdown](http://rmarkdown.rstudio.com). Pour obtenir les résultats de la vérification et la validation des données, exécutez les commandes contenues dans ce carnet de notes. Pour ce faire, positionnez votre curseur à l'intérieur d'une boîte de commandes et cliquez sur la flèche verte à la droite de celle-ci nommée *Run Current Chunk* ou appuyez sur les touches *Ctrl+Maj+Entrée* (*Cmd-Maj+Entrée* sur *macOS*) de votre clavier. Répétez pour chaque boîte de commandes. À mesure que les commandes contenues dans ce carnet seront exécutées, les résultats apparaîtront sous chacune des commandes correspondantes dans la présente fenêtre. Une fois toutes les commandes exécutées, cliquez sur le bouton *Preview* en haut à gauche de la présente fenêtre ou appuyer sur les touches *Ctrl+Maj+K*. Une nouvelle fenêtre apparaîtra et contiendra le rapport de ces résultats de la vérification et la validation des données générales RCBA.

##Prérequis

```{r include=FALSE}
## Required Packages and Custom Functions
source("../../../Required_packages.R")
source("../../../Required_functions.R")


## Project Preferences
source("../../../Configuration/project_settings.R")

```

Ce carnet suppose que vous avez importé vos données dans *R* en utilisant le carnet d'importation de données (AED_Importation.Rmd).

Le fichier contenant les donneés d'habitat de ce projet est **`r if(is.data.frame(dataset.ENV)) "présent" else "absent. Veuillez ouvrir et exécuter le carnet 'RCBA_vv_importation.Rmd' avant d'exécuter le présent carnet"`**.

##Statistiques descriptives

Le fichier de données contient `r nrow(dataset.ENV) ` visites (lignes) et `r ncol(dataset.ENV) ` taxons (colonnes).

Le tableau suivant présente une partie des données du fichier.

**Lecture des données d'habitat**

`r head(dataset.ENV) `

> ![ACTION:](../../../Configuration/action.png)
> *Vérifiez les données et assurez-vous que cela réflète bien la réalité. Examinez particulièrement les éléments suivants:*
>
> - *Le fichier semble-t'il avoir été lu correctement?*
> - *Des colonnes sont-elles manquantes?*

**Liste des visites présentes dans les données d'habitat (ID provenant de la base de données RCBA) :**  

`r rownames(dataset.ENV) `

> ![ACTION:](../../../Configuration/action.png)
> *Vérifiez les données et assurez-vous que cela réflète bien la réalité. Comparez la liste ci-haut avec le tableau suivant qui présente les visites présentes dans l'un ou l'autre des fichiers de données pour vous assurez que tout est adéquat.


`r formattable(dataset.NAM, align = "c", row.names = TRUE)`

**Liste des variables :**  

`r colnames(dataset.ENV) `

> ![ACTION:](../../../Configuration/action.png)
> *Vérifiez les variables ci-haut et assurez-vous qu'elles sont toutes présentes.


###Statistiques générales

Le tableau suivant présente les statistiques générales par variable. Lorsque le résultat obtenu à la ligne *BinaryData* du tableau est *TRUE*, cela indique que la variable présente des données binaires. Cependant, ce résultat peut également n'être obtenu que parce que la variable ne présente qu'une à deux données au maximum. La ligne *Na.values* indique le nombre de valeurs manquantes que présente chaque variable.

**Tableau des statistiques générales**

```{r, echo=FALSE}

#Tableau des paramètres généraux par variable

{summary.ENV <- as.data.frame(t(do.call(cbind, lapply(dataset.ENV, summary))))
summary.ENV$Std.deviation <- apply(dataset.ENV, 2, sd, na.rm = T)
summary.ENV$Length <- colSums(!is.na(dataset.ENV))
summary.ENV$BinaryData <- sapply(dataset.ENV,function(x)length(unique(na.omit(x)))<=2)
summary.ENV$NA.values <- colSums(is.na(dataset.ENV))
summary.ENV$`NA's` <- NULL
summary.ENV <- as.data.frame(t(summary.ENV))
summary.ENV
}
formattable(summary.ENV, digits = 2, align = "c")

```

> ![ACTION:](../../../Configuration/action.png)
> *Vérifiez les données et assurez-vous qu'elles réflètent bien la réalité. Examinez les statistiques de base et identifiez, le cas échéant, des anomalies au niveaux des statistiques de base.

##Localisation des données environnementales

###Distribution géographique des variables d'habitat

Les graphiques suivants illustrent la position (latitude et longitude) ainsi que la valeur observée des variables dans le fichier de données d'habitat.

```{r, echo=FALSE, warning=FALSE}
#Distribution géographique des valeurs des variables d'habitat

dataset.ENV2 <- rownames_to_column(dataset.ENV, var = "rownames")
dataset.GEN2 <- rownames_to_column(dataset.GEN, var = "rownames")
dataset.ENV2 <- left_join(dataset.ENV2, dataset.GEN2[,c("rownames", "Longitude", "Latitude")], by = "rownames")

size <- dataset.ENV2[2:ncol(dataset.ENV2)]
size[c(length(size)-2,length(size)-1, length(size))] <- NA

for(i in 2:(ncol(dataset.ENV2)-7)){
graph.geo.ab <- ggplot(dataset.ENV2, aes(Longitude, Latitude)) +
  geom_point(shape = 21, aes(size = size[i-1])) +
  ggtitle(paste("Distribution géographique de la variable\n", colnames(dataset.ENV2[i]))) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_size(range = c(1,10), name = "Valeur")
graph.geo.ab
print(graph.geo.ab)
}

rm(size)
rm(dataset.GEN2)
```


###Cartographie de la distribution de l'altitude par site

La carte interactive suivante illustre la position des sites en fonction des coordonnées géographiques contenues dans le fichier de données ainsi que l'altitude par site. Cliquez sur le marqueur d'une visite pour indiquer l'altitude observée dans celle-ci.

```{r, echo=FALSE, fig.height=5.5, fig.width=8.5, message=FALSE, include=TRUE}
#Cartographie de la distribution de l'altitude par site

dataset.SPA2 <- rownames_to_column(dataset.SPA, var = "rownames")
dataset.NAM2 <- rownames_to_column(dataset.NAM, var = "rownames")
dataset.SPA2 <- left_join(dataset.SPA2, dataset.NAM2[, c("rownames", "Site", "SampleDate", "SampleNumber")], by = "rownames")
dataset.SPA2$Site_Date_Number <- paste(dataset.SPA2$Site, "_", dataset.SPA2$SampleDate, "_", dataset.SPA2$SampleNumber)
dates <- as.Date(dataset.SPA2$SampleDate, "%Y-%m-%d")
dataset.SPA2$Year <- strftime(parse_date_time(as.character(dates), "%Y-%m-%d"), "%y")
dataset.SPA2$Site_Year <- paste(dataset.SPA2$Site, "_", dataset.SPA2$Year)

cabinPoints <- SpatialPointsDataFrame(coords = dataset.SPA[, 1:2], data = dataset.SPA)
  
getColor2 <- function(dataset.SPA2) {
  sapply(dataset.SPA2$SampleDate, function(SampleDate) {
  if(SampleDate <= "2005-12-31") {
    "green"
  } else if(SampleDate <= "2006-12-31") {
    "yellow"
  } else if(SampleDate <= "2007-12-31") {
    "darkorange"
  } else if(SampleDate <= "2008-12-31") {
    "red"
  } else if(SampleDate <= "2009-12-31") {
    "pink"
  } else if(SampleDate <= "2010-12-31") {
    "blue"
  } else if(SampleDate <= "2011-12-31") {
    "darkgreen"
  } else if(SampleDate <= "2012-12-31") {
    "cyan"
  } else if(SampleDate <= "2013-12-31") {
    "deeppink"
  } else if(SampleDate <= "2014-12-31") {
    "lightblue"
  } else if(SampleDate <= "2015-12-31") {
    "lightseagreen"
  } else if(SampleDate <= "2016-12-31") {
    "darkviolet"
  } else if(SampleDate <= "2017-12-31") {
    "darkred"
  } else if(SampleDate <= "2018-12-31") {
    "cadetblue"
  } else if(SampleDate <= "2019-12-31") {
    "black"
  } else if(SampleDate <= "2020-12-31") {
    "gray"
  } else {
    "brown"
  } })
} 

#dates <- as.Date(dataset.SPA2$SampleDate, "%Y-%m-%d") 
#dataset.SPA2$Year <- strftime(parse_date_time(as.character(dates), "%Y-%m-%d"), "%Y")

  leaflet(data = dataset.SPA2) %>% addProviderTiles(providers$Esri.WorldTopoMap) %>% addCircleMarkers(~Longitude, ~Latitude, popup = paste( "Station_Année : ", dataset.SPA2$Site_Year, "<br>", "Altitude : ", dataset.ENV2$Altitude, "<br>"), label = (dataset.SPA2$Site_Year), radius = dataset.ENV2$Altitude, color = getColor2(dataset.SPA2), stroke = F, fillOpacity = 0.5, clusterOptions = markerClusterOptions()) %>% addLegend(
  position = 'bottomright',
  colors = palette(),
  labels = palette(),
  opacity = 1,
  title = 'Légende')
  
rm(dataset.SPA2)

```


##Présence de données aberrantes

###Dispersion des valeurs observées

Les diagrammes de dispersion suivants présentent la valeur des données de variables continues observées dans le fichier de données dans l'ordre à laquelle elles apparaissent dans ce fichier pour chaque variable. Sous l'axe des X se trouve l'identifiant de la visite vis-à-vis la valeur observée correspondante, soit le nom du site d'où provient la donnée, sa date d'échantillonnage et le nombre d'échantillonnage pris pour cette donnée.

> ![ACTION:](../../../Configuration/action.png)
> *Vérifier les données et assurez-vous qu'elles réflètent bien la réalité. Examinez les points suivants :*
>
> - *Des données sortent-elles de l'ordinaire?*


```{r, echo=FALSE, warning=FALSE}
#Diagrammes de dispersion des valeurs observées par variable d'habitat

dataset.NAM2$Site_Date_Number <- paste(dataset.NAM2$Site, "_", dataset.NAM2$SampleDate, "_", dataset.NAM2$SampleNumber)
dataset.ENV2 <- left_join(dataset.ENV2, dataset.NAM2[,c("rownames", "Site_Date_Number")], by = "rownames")

for(j in 2:(ncol(dataset.ENV2)-7)){
plot.ab <- ggplot(dataset.ENV2, aes(x = dataset.ENV2$Site_Date_Number, y = dataset.ENV2[,j])) +
  geom_point() +
  labs(y = "Valeur", x = "Visite") +
  theme(axis.text.x = element_text(angle = 90, vjust = -0.05)) +
   scale_x_discrete(breaks = ifelse(!is.na(dataset.ENV2[,j]), dataset.ENV2$Site_Date_Number, ""), labels = ifelse(!is.na(dataset.ENV2[,j]), dataset.ENV2$Site_Date_Number, ""), na.value = NA) +
  theme(plot.title = element_text(hjust = 0.5)) +
  ggtitle(paste("Valeurs observées de\n", colnames(dataset.ENV2[j])))
plot.ab
print(plot.ab)
}

```

###Boîtes à moustaches des valeurs observées et transformées

La première boîte à moustaches (à gauche) présentent la distribution des valeurs de variables continues observées dans le fichier de données et la deuxième boîte à moustaches (à droite) présentent la distribution des valeurs de variables continues observées ayant subies une transformation logarithmique. 

> ![ACTION:](../../../Configuration/action.png)
> *Vérifiez les données et assurez-vous que cela réflète bien la réalité. Examinez particulièrement les éléments suivants:*
>
> - *Des données semblent-elles sortir de l'ordinaire?*

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#Boîtes à moustaches des valeurs observées et transformées

for(i in 2:(ncol(dataset.ENV2)-7)){
box.ab.1 <- qplot(y = dataset.ENV2[,i], x = "", geom = "boxplot", ylab = colnames(dataset.ENV2[i])) + 
  theme(plot.title = element_text(hjust = 0.5)) +
  ggtitle(paste("Distribution des valeurs observées\npour", colnames(dataset.ENV2[i])))
box.ab.2 <- qplot(y = dataset.ENV2[,i], x = "", geom = "boxplot", ylab = paste("Log(", colnames(dataset.ENV2[i]),")"), log = "y") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  ggtitle(paste("Distribution de log(valeurs observées)\npour", colnames(dataset.ENV2[i])))

grid.arrange(box.ab.1, box.ab.2, ncol = 2)
}

```



###Identification des données aberrantes potentielles

La première boîte à moustaches (à gauche) présentent la distribution des valeurs de variables continues observées dans le fichier de données et le diagramme de dispersion (à droite) présentent la distribution des valeurs de variables continues observées dans l'ordre à laquelle elles apparaissent dans ce fichier. Les données présentant une identification par leur identifiant sur les diagrammes représentent les données potentiellement aberrantes contenues dans le fichier de données. La méthode utilisée pour identifier les données potentiellement aberrantes est l'étendue interquantile (*Interquantile range* ou *IQR*). L'IQR se calcule de la manière suivante :

`IQR(x) = quantile(x, 3/4) - quantile(x, 1/4)`


Les valeurs potentiellement aberrantes sont définies comme des observations qui se situent au-dessous de *Q1 - 1,5 IQR* ou plus de *Q3 + 1,5 IQR*.

L'identifiant de la visite correspond au nom du site d'où provient la donnée, sa date d'échantillonnage et le nombre d'échantillonnage pris pour cette donnée.

> ![ACTION:](../../../Configuration/action.png)
> *Examinez les graphiques suivants et portez votre attention sur les points (si présents) auxquels un identifiant est associé. Posez-vous la question suivante :*
>
> - *Les données potentiellement aberrantes le sont-elles vraiment?*


```{r, echo=FALSE, warning=FALSE}
#Identification des données aberrantes potentielles

for (j in 2:(ncol(dataset.ENV2)-7)) {
  boxplot <- ggplot(data = dataset.ENV2, aes(x = "", y = dataset.ENV2[,j])) +
    geom_boxplot() +
    ylab("Valeur") +
    xlab("") +
    theme(plot.title = element_text(hjust = 0.5)) +
    ggtitle(paste("Valeurs observées de la\nvariable", colnames(dataset.ENV2[j]))) +
    geom_text(aes(label = ifelse(dataset.ENV2[,j] < quantile(dataset.ENV2[,j], probs=c(.25), na.rm = T) - 1.5*IQR(dataset.ENV2[,j], na.rm = T)|dataset.ENV2[,j] > quantile(dataset.ENV2[,j], probs=c(.75), na.rm = T) + 1.5*IQR(dataset.ENV2[,j], na.rm = T), dataset.ENV2$Site_Date_Number, "")), hjust = -0.05, size = 3)

  dotchart <- ggplot(data = dataset.ENV2, aes(y = seq(dataset.ENV2[,j]), x = dataset.ENV2[,j], na.rm = T)) +
    geom_point(na.rm = T) +
    ylab("Ordre des données") +
    xlab("Valeur") +
    theme(plot.title = element_text(hjust = 0.5)) +
    ggtitle(paste("Distribution des valeurs\nobservées de la variable\n", colnames(dataset.ENV2[j]))) +
    geom_text(aes(label = ifelse(dataset.ENV2[,j] < quantile(dataset.ENV2[,j], probs=c(.25), na.rm = T) - 1.5*IQR(dataset.ENV2[,j], na.rm = T)|dataset.ENV2[,j] > quantile(dataset.ENV2[,j], probs=c(.75), na.rm = T) + 1.5*IQR(dataset.ENV2[,j], na.rm = T), dataset.ENV2$Site_Date_Number, "")), hjust = -0.05, nudge_y = 2, size = 3)
        
  grid.arrange(boxplot, dotchart, ncol = 2)
}
```

La liste suivante présente les données potentiellement aberrantes contenues dans le fichier de données pour chaque variable. Lorsque l'identifiant d'une donnée y est indiqué, cela indique que cette donnée représente une donnée potentiellement aberrante contenue dans le fichier de données. Les mentions *""* indiquent les données non aberrantes et les mentions *NA* indiquent la présence de valeurs manquantes. L'identifiant de la visite correspond au nom du site d'où provient la donnée, sa date d'échantillonnage et le nombre d'échantillonnage pris pour cette donnée.

```{r, echo=FALSE, warning=FALSE}
#Identification des données aberrantes potentielles (suite)

for (j in 2:(ncol(dataset.ENV2)-7)) {
print(colnames(dataset.ENV2[j]))
list <- list(ifelse(dataset.ENV2[,j] < quantile(dataset.ENV2[,j], probs=c(.25), na.rm = T) - 1.5*IQR(dataset.ENV2[,j], na.rm = T) | dataset.ENV2[,j] > quantile(dataset.ENV2[,j], probs=c(.75), na.rm = T) + 1.5*IQR(dataset.ENV2[,j], na.rm = T), dataset.ENV2$Site_Date_Number, ""))
print(list)
}

```


##Normalité des données 

###Diagrammes Quantile-Quantile et histogrammes de fréquences

Pour chaque variable, le premier graphique (à gauche) illustre la distribution observée des valeurs par variable par des points et la distribution normale théorique calculée à partir des paramètres de la distribution observée par une droite. Plus les valeurs observées sont positionnées sur la droite, plus celles-ci sont distribuées selon la loi normale.

Le deuxième graphique (au milieu) illustre par un histogramme la distribution des fréquences des valeurs observées par taxon. Cet histogramme illustre également la valeur moyenne par variable par une ligne pleine ainsi que l'écart-type des variables par deux lignes pointillées.

Le troisième graphique (à droite) illustre la distribution des fréquences des valeurs observées par variable ayant subies une transformation logarithmique. Si la distribution des données sur ce dernier graphique semble ressembler davantage à une distribution normale, une transformation logarithmique des données pourrait être nécessaire. Cet histogramme illustre également la valeur moyenne par variable par une ligne pleine ainsi que l'écart-type des variables par deux lignes pointillées.

```{r, echo=FALSE}
#Diagrammes Quantile-Quantile et histogrammes de fréquences

for (i in 1:ncol(dataset.ENV)){
	norm.mean <- mean(which(!is.na(dataset.ENV[,i])))
	norm.sd <- sd(which(!is.na(dataset.ENV[,i])))
	norm.n <- length(which(!is.na(dataset.ENV[,i])))
	norm.bin <- ceiling(max(which(!is.na(dataset.ENV[,i])))- min(which(!is.na(dataset.ENV[,i])))/nclass.Sturges(which(!is.na(dataset.ENV[,i]))))

	par(mfrow = c(1,3), oma=c(1,1,2,1))

	qqnorm(which(!is.na(dataset.ENV[,i])), main = "Diagramme Quantile-Quantile", xlab = "Quantiles de la loi normale", ylab = "Quantiles normalisés observés")
	qqline(which(!is.na(dataset.ENV[,i])),lty = 2)

	hist.ab <- hist(as.numeric(unlist(dataset.ENV[,i])), breaks = "Sturges", xlab = "Valeur", ylab = "Fréquence", main = "Fréquences d'abondances")
	xfit <- seq(min(which(!is.na(dataset.ENV[,i]))), max(which(!is.na(dataset.ENV[,i]))), length=norm.n)
	yfit_density <- dnorm(xfit, mean = norm.mean, sd=norm.sd)
	yfit_freq <- yfit_density*diff(hist.ab$mids[1:2])*norm.n
	lines(xfit, yfit_freq, col="red", lwd=1)
	  abline(v = norm.mean, col = "blue") +
	  abline(v = norm.mean + norm.sd, lty = 2, col = "blue") +
	  abline(v = norm.mean - norm.sd, lty = 2, col = "blue")

	norm.mean.log <- mean(log(which(!is.na(dataset.ENV[,i]))))
	norm.sd.log <- sd(log(which(!is.na(dataset.ENV[,i]))))
	norm.n.log <- length(log(which(!is.na(dataset.ENV[,i]))))
	norm.bin.log <- ceiling(max(log(which(!is.na(dataset.ENV[,i]))))- min(log(which(!is.na(dataset.ENV[,i]))))/nclass.Sturges(log(which(!is.na(dataset.ENV[,i])))))
  
	hist.ab.2 <- hist(log(as.numeric(unlist(dataset.ENV[,i]))), breaks = "Sturges", xlab = "Log(Abondance)", ylab = "Fréquence", main = "Fréquences d'abondances (log)")
	xfit <- seq(min(log(which(!is.na(dataset.ENV[,i])))), max(log(which(!is.na(dataset.ENV[,i])))), length=norm.n.log)
	yfit_density <- dnorm(xfit, mean = norm.mean.log, sd=norm.sd.log)
	yfit_freq <- yfit_density*diff(hist.ab.2$mids[1:2])*norm.n.log
	lines(xfit, yfit_freq, col="red", lwd=1)
	  abline(v = norm.mean.log, col = "blue") +
	  abline(v = norm.mean.log + norm.sd.log, lty = 2, col = "blue") +
	  abline(v = norm.mean.log - norm.sd.log, lty = 2, col = "blue")
	mtext(colnames(dataset.ENV[i]), cex = 1.2, outer = TRUE)

  }

```


###Boîtes à moustaches des valeurs observées par variable environnementale

Pour chaque variable, la première boîte à moustaches (à gauche) illustre la distribution des valeurs observées dans le fichier de données et la deuxième boîte à moustaches (à droite) illustre la distribution des valeurs observées dans le fichier de données ayant subies une transformation logarithmique.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#Boîtes à moustaches des valeurs observées par variable d'habitat

for(i in 1:ncol(dataset.ENV)){
box.ab.1 <- qplot(y = dataset.ENV[,i], x = "", geom = "boxplot", ylab = "Valeur") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  ggtitle(paste("Boite à moustaches pour\n", colnames(dataset.ENV[i])))
box.ab.2 <- qplot(y = dataset.ENV[,i], x = "", geom = "boxplot", ylab = "Log(Valeur)", log = "y") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  ggtitle(paste("Boite à moustaches pour\n", colnames(dataset.ENV[i])))

grid.arrange(box.ab.1, box.ab.2, ncol = 2)
}

```


###Tests de normalité

Les résultats suivants présentent le résultat obtenu par un test de Snows appliqué sur chaque variable du fichier de données. Une valeur de P (p-value) inférieure à 0.05 indique qu'il n'est pas possible de supposer que la distribution des données suit la loi normale avec une probabilité de 95%. 

```{r, echo=FALSE, warning=FALSE}
#Tests de normalité de Snows par variable

apply(dataset.ENV, 2, SnowsPenultimateNormalityTest)

#Une valeur de P (p-value) inférieure à 0.05 indique qu'il n'est pas possible de considérer que les données suivent une distribution normale. 

```


##Collinéarité des variables

###Matrice de diagrammes de disperson

La matrice de diagrammes de dispersion suivante illustre la relation qui existe entre des pairs de variables. Elle permet notamment de détecter la présence de corrélations entre des variables.

```{r, echo=FALSE}
#Matrice de corrélation entre les variables

dataset.ENV[is.na(dataset.ENV)] <- 0

AllS <- names(dataset.ENV)
Env <- dataset.ENV[,AllS]

PlotMatrix(Env, panel = panel.smooth)

dataset.ENV[dataset.ENV == 0] <- NA

```


###Indépendance temporelle des variables

Pour chaque variable, le premier graphique (en haut à gauche) illustre la valeur observée des données selon leur année d'échantillonnage. Le deuxième graphique (en haut à droite) illustre les tendances observées de variations des valeurs des données dans le temps. Le troisième graphique (en bas à gauche) illustre les prévisions futures de variations des valeurs dans le temps. Sur ce graphique la ligne bleue correspond à la tendance attendue moyenne de variations dans le temps, la zone grise foncée correspond à un intervalle de confiance de 80% et la zone grise pâle correspond à un intervalle de confiance de 95%. Le quatrième graphique (en bas à droite) illustre l'autocorrélation de séries temporelles (ACF). Une valeur d'autocorrélation  supérieure à l'intervalle de confiance de 95% illustrée par la ligne pointillée indique une possible dépendance entre la variable et la période de l'année (temps). Par exemple, une certaine valeur d'une variable observée lors d'une année précise pourrait être expliquée par un certain événement datant d'une année antérieure (décalage dans le temps en années). Il est à noter que l'autocorrélation au temps de décalage 0 est, par définition, égale à 1.

```{r echo=FALSE}
#Indépendance temporelle des variables

dataset.ENV2 <- left_join(dataset.ENV2, dataset.NAM2[,c("rownames", "SampleDate")], by = "rownames")

dataset.ENV2[is.na(dataset.ENV2)] <- 0

for(i in 2:(ncol(dataset.ENV2)-4)){
  par(mfrow = c(2, 2), oma = c(1,1,2,1))
  graph.time <- plot(dataset.ENV2$SampleDate, dataset.ENV2[,i], xlab = "Année", ylab = "Valeur", main = "Valeurs observées")

  graph.time2 <- ts(dataset.ENV2[,i], frequency = 12, start = c(2005-01-01), end = c(2016-01-01))
  plot(graph.time2, xlab = "Année", ylab = "Valeur", main = "Valeurs prédites")

  auto.arima <- auto.arima(graph.time2)
  graph.auto.arima <- plot(forecast(auto.arima, h = 120), main = "Prévision (ARIMA)", xlab = "Année")
  
  graph.lag <- acf(graph.time2, xlab = "Décalage (années)", ylab = "ACF", main = "Fonction d'autocorrélation", ylim = c(0, 1))
  mtext(colnames(dataset.ENV2[i]), cex = 1.2, outer = TRUE)
}

dataset.ENV2[dataset.ENV2 == 0] <- NA

#rm(dataset.NAM2)

```

Plus bas se trouvent les résultats du test de la statistique de Ljung–Box appliqué sur chaque variable et confirment les résultats illustrés par les graphiques précédents. Une valeur de P (p-value) inférieure à 0.05 permet de supposer que les valeurs résiduelles d'une variable dépendent de la période de l'année (temps).

```{r, echo=FALSE}
#Indépendance temporelle des variables (suite)

dataset.ENV2[is.na(dataset.ENV2)] <- 0

for(i in 2:(ncol(dataset.ENV2)-4)){
  graph.time2 <- ts(dataset.ENV2[,i], frequency = 12, start = c(2005-01-01), end = c(2016-01-01))
  auto.arima <- auto.arima(graph.time2)
  box <- lapply(1:20, function(j) Box.test (resid(auto.arima), lag = j, type="Ljung"))
  print(paste(colnames(dataset.ENV2[i])))  
  print(box)
}

dataset.ENV2[dataset.ENV2 == 0] <- NA

```

##Notes sur les versions
**Quoi de nouveau, mis à jour ou corrigé dans cette version**

***
![ACTION:](../../../Configuration/logo_new.png) Nouveau &nbsp;&nbsp;&nbsp;   ![ACTION:](../../../Configuration/logo_updated.png) Mise à jour &nbsp;&nbsp;&nbsp;  ![ACTION:](../../../Configuration/logo_fixed.png) Corrigé

***

**RCBA_vv_habitat.Rmd Version 1.1 — 1er novembre 2017**

Cette version présente des suggestions d'actions en rapport avec la vérification et validation des données générales.

![ACTION:](../../../Configuration/logo_new.png)   **Actions**.

**RCBA_vv_habitat.Rmd Version 1.0 — 18 août 2017**

Version initiale de l'outil de vérification et validation des données d'habitat.

![ACTION:](../../../Configuration/logo_new.png)   **Première version**.


***

Développé par [Martin Jean](mailto:martin.jean@canada.ca) et Evelyne Paquette-Boisclair
